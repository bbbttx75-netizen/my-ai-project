import streamlit as st 
from transformers import pipeline

# @st.cache_resource # ููููู ุฅุถุงูุชู ูุงุญูุงู ุจุนุฏ ุงูุชุฃูุฏ ูู ุนูู ุงูุชุทุจูู
def load_model(): 
    # ูููุฐุฌ DistilGPT2 (ุงููุตุบุฑ) ูุถูุงู ุงูุนูู ุนูู Streamlit Sharing 
    return pipeline("text-generation", model="distilgpt2") 

# ูุชู ุชุญููู ุงููููุฐุฌ ูุฑุฉ ูุงุญุฏุฉ
chatbot_pipeline = load_model() 

# ูุงุฌูุฉ ุงููุณุชุฎุฏู ูุงูุชุตููู 
st.set_page_config(page_title="ุงูุฃุณุทูุฑุฉ", layout="wide") 
st.title("๐งโโ๏ธ ูููุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุชูููุฏ ุงููุตูุต") 

# ุตูุฏูู ุฅุฏุฎุงู ุงููุต
prompt = st.text_area("ุฃุฏุฎู ุงููุต ุงูุฃููู (Prompt) ููุง:", "ุฑุญูุฉ ุงููุงุณุชุฑ ุจุฏุฃุช ุจู")

if st.button("ุชูููุฏ ุงููุต"):
    if prompt:
        with st.spinner("ุฌุงุฑู ุชูููุฏ ุงููุต... ูุฏ ูุณุชุบุฑู ุงูุฃูุฑ ุจุนุถ ุงูููุช..."):
            # ุชูููุฏ ุงููุต ุจุงุณุชุฎุฏุงู ุงููููุฐุฌ
            result = chatbot_pipeline(prompt, max_length=150, num_return_sequences=1)
            
            # ุนุฑุถ ุงููุชูุฌุฉ
            st.subheader("ุงููุชูุฌุฉ:")
            st.code(result[0]['generated_text'])
    else:
        # ูุฐุง ูู ุงูุณุทุฑ ุงูุฐู ูุงู ุจู ุฎุทุฃ ูู ุงูุจุฏุงูุฉ 
        st.error("ุงูุฑุฌุงุก ุฅุฏุฎุงู ูุต ุฃููู ูุจุฏุก ุงูุชูููุฏ.")

 

