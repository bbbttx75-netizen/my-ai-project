# ----------------------------------------------------
# app.py - ÙƒÙˆØ¯ Streamlit Ø§Ù„Ù†Ø¸ÙŠÙ (Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙ‚Ø·)
# ----------------------------------------------------
import streamlit as st
from transformers import pipeline

@st.cache_resource
def load_model():
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ GPT-2 Ø§Ù„Ø®ÙÙŠÙ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ
    return pipeline("text-generation", model="gpt2")

chatbot_pipeline = load_model()

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
st.set_page_config(page_title="Ù…Ù†ØµØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø£Ø³Ø·ÙˆØ±ÙŠØ©", layout="wide")
st.title("ğŸ¤– Ø¬Ù…ÙŠÙ†ÙŠ Ù…Ø§Ø³ØªØ± Ø¬Ø±Ø§Ù†Ø¯ - Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª")

# ØªÙ‡ÙŠØ¦Ø© Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"}]

# Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯
def generate_response(prompt_input):
    full_prompt = "System: Ø£Ù†Øª Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø­ØªØ±Ù ÙˆØ£Ø³Ø·ÙˆØ±ÙŠ.\n"
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            full_prompt += f"User: {msg['content']}\n"
        elif msg["role"] == "assistant":
            full_prompt += f"Assistant: {msg['content']}\n"

    full_prompt += f"User: {prompt_input}\nAssistant:"

    output = chatbot_pipeline(
        full_prompt, 
        max_new_tokens=100, 
        temperature=0.8,
        pad_token_id=chatbot_pipeline.tokenizer.eos_token_id
    )
    response = output[0]['generated_text'].split('Assistant:')[-1].strip()
    return response

# Ù…Ø±Ø¨Ø¹ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    with st.spinner("Ø§Ù„Ù…Ø§Ø³ØªØ± ÙŠÙÙƒØ±..."):
        response = generate_response(prompt)

    st.session_state.messages.append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)
